{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 52912\n",
      "RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png A\n",
      "SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png A\n",
      "Um9tYW5hIEJvbGQucGZi.png A\n",
      "B 52912\n",
      "TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png B\n",
      "C 52912\n",
      "D 52912\n",
      "VHJhbnNpdCBCb2xkLnR0Zg==.png D\n",
      "E 52912\n",
      "F 52912\n",
      "G 52912\n",
      "H 52912\n",
      "I 52912\n",
      "J 52911\n",
      "529114\n",
      "A 1872\n",
      "B 1873\n",
      "C 1873\n",
      "D 1873\n",
      "E 1873\n",
      "F 1872\n",
      "G 1872\n",
      "H 1872\n",
      "I 1872\n",
      "J 1872\n",
      "18724\n",
      "(529114, 784) (529114, 10)\n",
      "(18724, 784) (18724, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = list(), list()\n",
    "x_test, y_test = list(), list()\n",
    "\n",
    "train_letters = os.listdir(\"./notMNIST_large\")\n",
    "test_letters = os.listdir(\"./notMNIST_small\")\n",
    "\n",
    "count = 0;\n",
    "for i, letter in enumerate(train_letters):\n",
    "    fonts = os.listdir(\"./notMNIST_large/\" + letter)\n",
    "    print(str(letter)+ \" \" + str(len(fonts)))\n",
    "    for j, font in enumerate(fonts):\n",
    "        img = None\n",
    "        try:\n",
    "            img = plt.imread(\"./notMNIST_large/\"+ letter + \"/\" + font)\n",
    "        except:\n",
    "            print(font + \" \" + letter)\n",
    "        if img is None :\n",
    "            count -= 1\n",
    "            continue\n",
    "        x_train.append(img.reshape([28*28]))\n",
    "        y_train.append(np.zeros(10))\n",
    "        y_train[count + j][i] = 1\n",
    "    count += len(fonts)\n",
    "print(count)\n",
    "\n",
    "count = 0;\n",
    "for i, letter in enumerate(test_letters):\n",
    "    fonts = os.listdir(\"./notMNIST_small/\" + letter)\n",
    "    print(str(letter)+ \" \" + str(len(fonts)))\n",
    "    for j, font in enumerate(fonts):\n",
    "        img = None\n",
    "        try:\n",
    "            img = plt.imread(\"./notMNIST_small/\"+ letter + \"/\" + font)\n",
    "        except:\n",
    "            print(font + \" \" + letter)\n",
    "            #plt.imshow(img)\n",
    "        #plt.imshow(img)\n",
    "        if img is None :\n",
    "            count -= 1\n",
    "            continue\n",
    "        x_test.append(img.reshape([28*28]))\n",
    "        y_test.append(np.zeros(10))\n",
    "        y_test[count + j][i] = 1\n",
    "    count += len(fonts)\n",
    "print(count)\n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "x_test = np.asarray(x_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(a,b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = shuffle(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAATtElEQVR4nO3de3CV5Z0H8O8vyUkwhDsCEdAqghZcCxrQFnfFeqPWWaC2O7o7lk5dkRZ2dOrs1KXOlt2Zdd2LWi+tKypKO66Ms+pKV61c6sBaWUugLBdTrsM9TVBcuYfknN/+kZfdFPP8nsP7nnPeA8/3M5NJcn55z/twki9vcn7neR5RVRDR2a8i7QEQUWkw7ESBYNiJAsGwEwWCYScKRFUpT1YtNdoDPUt5yrODiF03Oirau9Y8dMDwT816j4oTZn1X8yCzXvXREbNOhXUcR3BC27r9gUkUdhGZDOBxAJUAnlPVh62v74GeuEquT3LKIEmm2qxruzuQbdeMN4+989Gfm/UxNXvN+uyHZpv1Ac+tdBcrKs1jkcvadfqMD3SZsxb713gRqQTwYwBfATAawB0iMjru/RFRcSX5m30CgK2qul1VTwBYCGBKYYZFRIWWJOxDAezu8vme6LbfIyIzRKRRRBrb0ZbgdESURJKwd/ckwGeeKVLVearaoKoNGdQkOB0RJZEk7HsADO/y+TAA+5INh4iKJUnYVwEYKSIXikg1gNsBLCrMsIio0GK33lS1Q0RmA3gHna23+aq6sWAjC4mnBWW11gDg2NQJztpTP3rCPPby6h5mvfNb67Zi7uNm/Uu19zlrg5943z41W3MFlajPrqpvAXirQGMhoiLiy2WJAsGwEwWCYScKBMNOFAiGnSgQDDtRIEo6nz1YCfvF0nCZWf/bR55z1nx99DZtN+sVnutBbYU9/XbxX/6Ts3bb7u/Z9/36B2ZdquwfX+3oMOuh4ZWdKBAMO1EgGHaiQDDsRIFg2IkCwbATBYKtt0LwLfXsaa1V1NrLPfd87HdmfdI5OWfto6y9lHOfCrs1lxG7behr3Q2qdC8dfudD9sq2b6y50qx37Nxt1s2WZ4DTY3llJwoEw04UCIadKBAMO1EgGHaiQDDsRIFg2IkCwT57IYjn/0y1e7pb//oLZn3LiKfN+uHccWdtoNHnzkdW3T18AKiRjFm3+vAz+th7ijz1+LVmvX6qWaZT8MpOFAiGnSgQDDtRIBh2okAw7ESBYNiJAsGwEwWCffZ8JZgbnb3uCrP+7p+6l1vuVGdWrV73hW/MMI8deuFHZv29y18z6+2e1xBYY/P18NdNeNmsj/2L75r1wU+6t4SWjL0Etm+b7DNRorCLyA4AhwBkAXSoakMhBkVEhVeIK/t1qmpfHogodfybnSgQScOuABaLyGoR6faPQxGZISKNItLYjraEpyOiuJL+Gj9RVfeJyCAAS0Tkt6q6ousXqOo8APMAoLf014TnI6KYEl3ZVXVf9L4VwOsAJhRiUERUeLHDLiI9RaTXyY8B3ARgQ6EGRkSFleTX+MEAXpfONdOrAPyrqv6iIKNKg2/td6sn7Dm2dq49b3tYld1H9xn19j3u2nd+bR5b2a+fWb9/qf0agUfq15h1Xx/e4tnoGt+b9YpZX/iOez58dvM2+84TbrNdjmKHXVW3A7BXXSCissHWG1EgGHaiQDDsRIFg2IkCwbATBYJTXCNSabdatKPDWWud9SXz2N+M/EmsMZ00p+Vys/75v9rprGU9bcHsJ5+Y9dUPjjfrnz77K7Pep+Ic97k9U1x920F/s7c9/2runL7O2shvmYeelXhlJwoEw04UCIadKBAMO1EgGHaiQDDsRIFg2IkCwT57xOqjA0Bl3z7O2uzZ9nLLPr5+8tLHJ5r1fvtXOmu+JZN9at5eZdaveNdeznnb9S84ax2Ivwx1Pppu/BdnbfJke9zVv7D/3WfiFFhe2YkCwbATBYJhJwoEw04UCIadKBAMO1EgGHaiQATTZ0+6Re/mH4x21u7qszzWmE66eeM3zHq/F919dABmz9e79bBvCW2PSx46bNbXXuPe8mtsTY15rG++e5I+/bkPbjeP/dS3KLpnbP6lyUu/ORKv7ESBYNiJAsGwEwWCYScKBMNOFAiGnSgQDDtRIM6ePrtnfrGv3yzjxpj1p6bNP+0hnXQ4d9ysZ/7O3jYZ2GGXfT1f81hPv9fzuGabtpj1216/11nbdrt7vjmQfL67tV30KxctM48dN8ue7z7ox++bdamyo+VbP6EYvFd2EZkvIq0isqHLbf1FZImIbIne+35aiShl+fwa/yKAyafc9gCAZao6EsCy6HMiKmPesKvqCgAHTrl5CoAF0ccLAEwt8LiIqMDiPkE3WFWbASB6P8j1hSIyQ0QaRaSxHe7XSRNRcRX92XhVnaeqDarakIE98YGIiidu2FtEpB4AovethRsSERVD3LAvAjA9+ng6gDcKMxwiKhZvn11EXgYwCcBAEdkD4IcAHgbwiojcBWAXAHtC9hlg08xasz65Nv7zDWNXzDTrI5b/xr6DMpwbna9LnnHvob74j+0++U32t8Tsoyd1+8wlZn35wuFmPfvxqc9pn8L6nhbp++kNu6re4ShdX+CxEFER8eWyRIFg2IkCwbATBYJhJwoEw04UiDNriqvVrvBskVs5epRZXzr5Mc/J65yVze1HzCPPn+/Z3tdDKj3Td4s5XdLzuPqW6M5u2uqszXzr2+ax27/+jFn3td5qK9xj8x37/QH21N2f/fmNZn3oP9hTYCHGdbZILUVe2YkCwbATBYJhJwoEw04UCIadKBAMO1EgGHaiQJxRfXar3+zrNTfd39usj8i4++g+0xpnmPVhS1eb9aTbSadJs/F7wpc+8z9mfdlX7dcXXH+O/bgVcwrs7On2Eg6Lnh5h1rMHD7qLRZrSzCs7USAYdqJAMOxEgWDYiQLBsBMFgmEnCgTDThSI8uqz+7ZdNnrpvvnqz1y7wKz7fJo75qyd9yO73+ujHe2Jjk+Vb767sXVxduMm89h7/uubZn3rdS+YdUtG7J81X49+Zt+9Zv2p70wx69Z8d6n2vO6iLd6y5ryyEwWCYScKBMNOFAiGnSgQDDtRIBh2okAw7ESBKKs+u3d9dKOnu+3PBpjH3lSbrJc9tel2Z636Pz1bLvuU8ZbLSSWZ737RT+zHJTspZ9Z9vXRLDvZ9A/Z9X3rrZrN+5En3ftS5o0ftU5vbPbtL3iu7iMwXkVYR2dDltrkisldE1kZvt/juh4jSlc+v8S8CmNzN7Y+p6tjo7a3CDouICs0bdlVdAeBACcZCREWU5Am62SKyLvo1v5/ri0Rkhog0ikhjO+K9ppeIkosb9qcBjAAwFkAzgEdcX6iq81S1QVUbMqiJeToiSipW2FW1RVWzqpoD8CyACYUdFhEVWqywi0h9l0+nAdjg+loiKg/ePruIvAxgEoCBIrIHwA8BTBKRsejs6u0AcE/eZzR6hL710SsH9HfWbr65Me8hxHH8hXpnrRo7zWOtOd1AkfdXP4PJyvVm/YYPp5n1d8e413ZvU/t1FzWSMeu++e7/NmKpWZ903d3uc7+5yjzW3Nvd4A27qt7Rzc3PxzobEaWGL5clCgTDThQIhp0oEAw7USAYdqJAlH6Kq9U28LQzjnzxYmftifPmxR0RAGBOy+Vmvd+Sbc6abxJnkmmeZzxj+m7SraoP/MdQ+9xj3KWsb1qxZ9fkpHZ+3T2FdtSbnoPVN/22e7yyEwWCYScKBMNOFAiGnSgQDDtRIBh2okAw7ESBKKulpH1231y85ufLK68266P2/9pZkxp7BZ64W+ye7ZK+/mDo0o/N+quzejtrt9UdNI/1TWGtSNiIf/BqdzP9FQyxD4659Div7ESBYNiJAsGwEwWCYScKBMNOFAiGnSgQDDtRIErfZ485FxcAvn3t8tjHNnccNusXvBl/22Rt51LQsRhbcAP++e7ZjZvM+pM7vuys3XbZv5vH+rZsrvBs2exzS8+tztpLN3zVPDazdHWsc/LKThQIhp0oEAw7USAYdqJAMOxEgWDYiQLBsBMFIoU+u7ufXTnmEvPQab1fNKrnmMf+8tgFZr3m7TVm3eTpF1NMCV6TAQAtvzrPXbzMPrYqYR896xl7fVWds9Yy3l4fYZi9G7ST98ouIsNF5F0RaRKRjSJyb3R7fxFZIiJbovf94g2BiEohn1/jOwDcr6qfB3A1gFkiMhrAAwCWqepIAMuiz4moTHnDrqrNqrom+vgQgCYAQwFMAbAg+rIFAKYWa5BElNxpPUEnIp8DMA7ABwAGq2oz0PkfAoBBjmNmiEijiDS2g2uxEaUl77CLSB2AVwHcp6r2an1dqOo8VW1Q1YYM7CceiKh48gq7iGTQGfSXVPW16OYWEamP6vUAWoszRCIqBG/rTUQEwPMAmlT10S6lRQCmA3g4ev9G0sG0frG/Wb84E79T+NCGyWZ9WG6jWbemW2pHu33ymEv//v/JEyxbbG2RDUAqEi7P7bn/RHxj67CnFp//jnta8+G7j5vH1lX0sM/tcTRnbzddK+6fp2OX2mOLK5/0TARwJ4D1IrI2um0OOkP+iojcBWAXgG8UZYREVBDesKvqe3BvTX99YYdDRMXCl8sSBYJhJwoEw04UCIadKBAMO1EgymrL5gNfsKcF1kgm9n3Lqj6xjwU82wsn7aN7T57g/j1bDyecRVrWKtZudtaWHhtoHju1p730uG8KaxKjL2g2655XdTjxyk4UCIadKBAMO1EgGHaiQDDsRIFg2IkCwbATBaKs+uyDRnxctPse8oE9Rzj3h+PMeuv97uNvOv+35rHj67ab9aM5ewWfpmPGksgAdh51rwOw+1Bf89gDh3qa9eMH7bFVfGr/CGUOua8nVcfMQ1Hpmdbde5f9GoJey7c4a3/z4a3msVPHLzTrOdivfchI/KWobzi3yawvvtj9syq73PPkeWUnCgTDThQIhp0oEAw7USAYdqJAMOxEgWDYiQJR0j67ZDKoGjLUWf9yvXv+sc+LB7vdfer/tNfZ/9Rb/36ZWZ/Sa52ztj9rbxfdrva5e2X2m/Ubau0+/bmD3L3wJGsAFJtvTnhlwjXpxzz5XWdNVnoOHm+X2z3rBNRI/Gh9rdcGs/7zC9yLOud+5z4vr+xEgWDYiQLBsBMFgmEnCgTDThQIhp0oEAw7USDy2Z99OICfAhgCIAdgnqo+LiJzAdwN4GSTeI6qvmXdl1ZXof1893rdk/u8meewP2vhPrsxWvtLe//1pX/Q267jGncx4brxUuOZM97Xs+Z9L/ec9FyvWvPQbE+7D9/ey1Ovs68XHee46+rZfr36iN2Hr91rT3gftvJ9Z+3o166yT+5RKcn2tW9T9+rv51fVmcceHez+nuQy7nHl0/nvAHC/qq4RkV4AVovIkqj2mKr+cx73QUQpy2d/9mYAzdHHh0SkCYD7ZXBEVJZO6292EfkcgHEAPohumi0i60Rkvoj0cxwzQ0QaRaSxveNIosESUXx5h11E6gC8CuA+VT0I4GkAIwCMReeV/5HujlPVearaoKoNmSp7vTMiKp68wi4iGXQG/SVVfQ0AVLVFVbOqmgPwLIAJxRsmESXlDbuICIDnATSp6qNdbq/v8mXTANhTdYgoVfk8Gz8RwJ0A1ovI2ui2OQDuEJGxABTADgD3+O4olxEcN6ZjXlXj24zW3XLYtM1ebnnUkb1mXTLuJXgBQNtPmPUktK3NrGdbWu07aIl/bt//9nZT0F8vqor4yzXX7jlq1le32d/vK2vsnxffFNis1a71dPWODHF/13JGpzSfZ+Pfc5ze7KkTUXnhK+iIAsGwEwWCYScKBMNOFAiGnSgQDDtRIEq6lLRWCo73dfdGkyx73GNvwiWTK5JNWUwk4XRJJFhyWZL+uxMu92zyLDXtO7fm3L3uquZPzGOXH7nUrF9ZYy/vnYNvmez4j/uxQe4efc5INK/sRIFg2IkCwbATBYJhJwoEw04UCIadKBAMO1EgRBMug3xaJxPZD2Bnl5sGAvioZAM4PeU6tnIdF8CxxVXIsV2gqud2Vyhp2D9zcpFGVW1IbQCGch1buY4L4NjiKtXY+Gs8USAYdqJApB32eSmf31KuYyvXcQEcW1wlGVuqf7MTUemkfWUnohJh2IkCkUrYRWSyiGwSka0i8kAaY3ARkR0isl5E1opIY8pjmS8irSKyoctt/UVkiYhsid53u8deSmObKyJ7o8durYjcktLYhovIuyLSJCIbReTe6PZUHztjXCV53Er+N7uIVALYDOBGAHsArAJwh6p+WNKBOIjIDgANqpr6CzBE5I8AHAbwU1W9LLrtHwEcUNWHo/8o+6nq98tkbHMBHE57G+9ot6L6rtuMA5gK4FtI8bEzxvUnKMHjlsaVfQKAraq6XVVPAFgIYEoK4yh7qroCwIFTbp4CYEH08QJ0/rCUnGNsZUFVm1V1TfTxIQAntxlP9bEzxlUSaYR9KIDdXT7fg/La710BLBaR1SIyI+3BdGOwqjYDnT88AAalPJ5TebfxLqVTthkvm8cuzvbnSaUR9u4W3yqn/t9EVb0CwFcAzIp+XaX85LWNd6l0s814WYi7/XlSaYR9D4DhXT4fBmBfCuPolqrui963Angd5bcVdcvJHXSj955dH0unnLbx7m6bcZTBY5fm9udphH0VgJEicqGIVAO4HcCiFMbxGSLSM3riBCLSE8BNKL+tqBcBmB59PB3AGymO5feUyzberm3GkfJjl/r256pa8jcAt6DzGfltAH6Qxhgc47oIwH9HbxvTHhuAl9H5a107On8jugvAAADLAGyJ3vcvo7H9DMB6AOvQGaz6lMZ2DTr/NFwHYG30dkvaj50xrpI8bny5LFEg+Ao6okAw7ESBYNiJAsGwEwWCYScKBMNOFAiGnSgQ/ws5geILV3aKSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = int(np.random.rand(1) * 18724)\n",
    "plt.imshow(x_train[i].reshape([28,28]))\n",
    "print(y_train[i])\n",
    "time.sleep(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    layers = list()\n",
    "    \n",
    "    w = list()\n",
    "    b = list()\n",
    "    \n",
    "    a = list()\n",
    "    z = list()\n",
    "    \n",
    "    da = list()\n",
    "    db = list()\n",
    "    dw = list()\n",
    "    \n",
    "    activators = list()\n",
    "    \n",
    "    depth = 0\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0,x)\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def drelu(self, x):\n",
    "        return x > 0\n",
    "    \n",
    "    def dsigmoid(self, x):\n",
    "        sigx = self.sigmoid(x)\n",
    "        return np.multiply(sigx, (1 - sigx))\n",
    "    \n",
    "    def __init__(self, input_size, layers_count, layers_size, activators, l_rate = 0.01):\n",
    "        self.layers = list()\n",
    "        self.w = list()\n",
    "        self.b = list()\n",
    "        self.a = list()\n",
    "        self.z = list()\n",
    "        \n",
    "        self.activators = activators\n",
    "        self.l_rate = l_rate\n",
    "        \n",
    "        self.layers.append(input_size)\n",
    "        self.a.append(0)\n",
    "        self.z.append(0)\n",
    "        for x in range(0,layers_count):\n",
    "            self.layers.append(layers_size[x])\n",
    "            self.a.append(0)\n",
    "            self.z.append(0)\n",
    "        \n",
    "        self.depth = len(self.layers)\n",
    "        \n",
    "        for x in range(1, self.depth):\n",
    "            #matarr = np.ndarray(shape=(self.layers[x-1], self.layers[x]))\n",
    "            matarr = np.random.normal(0,0.5, (self.layers[x-1], self.layers[x]))\n",
    "            mat = np.matrix(matarr)\n",
    "            self.w.append(mat)\n",
    "            #print(mat)\n",
    "            #barr = np.ndarray(self.layers[x])\n",
    "            barr = np.random.normal(0,0.5, self.layers[x])\n",
    "            #print(barr.shape)\n",
    "            #barr = barr.reshape((barr.shape[0], 1))\n",
    "            self.b.append(barr)\n",
    "        \n",
    "        \n",
    "    def predict(self,input):\n",
    "        self.a[0] = input\n",
    "        #print(self.a[0])\n",
    "        \n",
    "        for x in range(1,self.depth):\n",
    "            self.z[x] = np.matmul(self.a[x - 1], self.w[x - 1]) + self.b[x - 1]\n",
    "            if self.activators[x - 1] == \"sig\":\n",
    "                val = self.sigmoid(self.z[x])\n",
    "            elif self.activators[x - 1] == \"relu\":\n",
    "                val = self.relu(self.z[x])\n",
    "            self.a[x] = val\n",
    "            #print(\"wtf \" + str(x) + str(self.a[x]))\n",
    "        return self.a[self.depth - 1]\n",
    "    \n",
    "    def test(self, input, ans):\n",
    "        prediction = self.predict(input)\n",
    "        #c1 = np.array(list(np.array_equal(np.round(prediction[x]), ans[x]) for x in range(ans.shape[0])))\n",
    "        c1 = np.array(list(np.argmax(prediction[x]) == np.argmax(ans[x]) for x in range(ans.shape[0])))\n",
    "        #print(prediction)\n",
    "        \n",
    "        c = prediction - ans\n",
    "        c = np.square(c)\n",
    "        c = c.sum(axis = 1).mean()\n",
    "        return (c,c1.sum() / c1.shape[0])\n",
    "    \n",
    "    def train(self, input, ans):\n",
    "        prediction = self.predict(input)\n",
    "        #print(input.shape[0])\n",
    "        c = (prediction - ans)\n",
    "        c = np.square(c)\n",
    "        #print(c)\n",
    "        \n",
    "        prediction = np.swapaxes(prediction, 0,1)\n",
    "        ans = np.swapaxes(ans, 0,1)\n",
    "        \n",
    "        self.da = list() # dC(0)/da(Lj)\n",
    "        self.db = list() # dC(0)/db(Lj)\n",
    "        self.dw = list() # dC(0)/dw(Ljk)\n",
    "        \n",
    "        for i, x in enumerate(self.layers):\n",
    "            self.da.append(0)\n",
    "            self.db.append(0)\n",
    "            self.dw.append(0)\n",
    "        #print(len(self.db))\n",
    "        self.da[self.depth - 1] = 2 * (ans - prediction)\n",
    "        #print(self.da[self.depth - 1])\n",
    "        \n",
    "        #print(\"a\")\n",
    "        for x in range(self.depth - 2, 0, -1):\n",
    "            #print(x)\n",
    "            #print(self.w[x].shape, self.da[x+1].shape)\n",
    "            #a = np.asarray(np.matmul(self.w[x], da[x + 1]))\n",
    "            a = np.matmul(self.w[x], self.da[x + 1])\n",
    "            #print(a.shape)\n",
    "            #print(type(a))\n",
    "            #print(type(self.z[x]))\n",
    "            #print(a.shape, self.z[x].shape)\n",
    "            if self.activators[x - 1] == \"sig\":\n",
    "                #a = np.multiply(a, np.asarray(self.dsigmoid(self.z[x])))\n",
    "                a = np.multiply(a, np.swapaxes(self.dsigmoid(self.z[x]), 0, 1))\n",
    "            elif self.activators[x - 1] == \"relu\":\n",
    "                #a = np.multiply(a, np.asarray(self.drelu(self.z[x])))\n",
    "                a = np.multiply(a, np.swapaxes(self.drelu(self.z[x]), 0, 1))\n",
    "            #print(a)\n",
    "            #print(a.shape)\n",
    "            self.da[x] = a\n",
    "        #print(\"b\")\n",
    "        for x in range(1, self.depth):\n",
    "            #print(x)\n",
    "            if self.activators[x - 1] == \"sig\":\n",
    "                #a = np.multiply(a, np.asarray(self.dsigmoid(self.z[x])))\n",
    "                b = np.multiply(self.da[x], np.swapaxes(self.dsigmoid(self.z[x]), 0, 1))\n",
    "            elif self.activators[x - 1] == \"relu\":\n",
    "                #a = np.multiply(a, np.asarray(self.drelu(self.z[x])))\n",
    "                b = np.multiply(self.da[x], np.swapaxes(self.drelu(self.z[x]), 0, 1))\n",
    "            #print(b)\n",
    "            \n",
    "            self.db[x] = b\n",
    "            self.db[x] = np.mean(self.db[x], axis = 1)\n",
    "            #print(self.db[x].shape)\n",
    "            \n",
    "        #print(\"w\")\n",
    "        for x in range(1, self.depth):\n",
    "            \n",
    "            \n",
    "            _a = np.swapaxes(self.a[x - 1], 0, 1)\n",
    "            \n",
    "            w = np.zeros((_a.shape[0], self.da[x].shape[0], _a.shape[1]))\n",
    "            \n",
    "            for k in range(_a.shape[0]):\n",
    "                for j in range(self.da[x].shape[0]):\n",
    "                    w[k][j] = np.multiply(_a[k], self.da[x][j])\n",
    "            \n",
    "            self.dw[x] = w\n",
    "            self.dw[x] = np.mean(self.dw[x], axis = 2)\n",
    "            #print(self.dw[x].shape)\n",
    "        \n",
    "        for x in range(1, self.depth):\n",
    "            self.w[x - 1] += self.dw[x] * self.l_rate\n",
    "            \n",
    "            self.b[x - 1] = np.reshape(self.b[x - 1], (self.b[x - 1].shape[0], 1))\n",
    "            self.b[x - 1] += self.db[x] * self.l_rate\n",
    "            self.b[x - 1] = np.squeeze(self.b[x - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(784,2,(16,10), (\"relu\", \"sig\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = nn.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0673865069446165, 0.14890363891335326)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.train(x_train[:100], y_train[:100])\n",
    "nn.test(x_train, y_train)\n",
    "#nn.dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch finished!\n",
      "Train accuracy:  (1.700495914282863, 0.16952112399218316)\n",
      "Test accuracy:  (1.6803644699982319, 0.17976928006836146)\n",
      "epoch finished!\n",
      "Train accuracy:  (1.3921432691100257, 0.21253453887064036)\n",
      "Test accuracy:  (1.366506093813664, 0.22788933988464002)\n",
      "epoch finished!\n",
      "Train accuracy:  (1.1989658181023084, 0.23687900906042933)\n",
      "Test accuracy:  (1.1713884400216534, 0.25875881221961117)\n",
      "epoch finished!\n",
      "Train accuracy:  (1.1575609495422454, 0.2638618520772461)\n",
      "Test accuracy:  (1.1275170367174303, 0.28407391582995084)\n"
     ]
    }
   ],
   "source": [
    "batches = 10\n",
    "epochs = 10\n",
    "\n",
    "nn.l_rate = 0.01\n",
    "batch_length = int(np.floor(x_train.shape[0] / (batches)))\n",
    "for y in range(epochs):\n",
    "    for x in range(batches + 1):\n",
    "        if x == batches:\n",
    "            if x_train.shape[0] != batch_length * batches:\n",
    "                nn.train(x_train[batch_length * batches:], y_train[batch_length * batches:])\n",
    "            break\n",
    "        nn.train(x_train[batch_length * x : batch_length * (x + 1) - 1], y_train[batch_length * x : batch_length * (x + 1) - 1])\n",
    "        print(\"\\r\",\"Batch: \" , x ,\"Train accuracy: \", nn.test(x_train, y_train), \"Test accuracy: \", nn.test(x_test, y_test))\n",
    "    #print(\"epoch finished!\")\n",
    "    x_train, y_train = shuffle(x_train,y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
