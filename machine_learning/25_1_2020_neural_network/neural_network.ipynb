{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 52912\n",
      "RnJlaWdodERpc3BCb29rSXRhbGljLnR0Zg==.png A\n",
      "SG90IE11c3RhcmQgQlROIFBvc3Rlci50dGY=.png A\n",
      "Um9tYW5hIEJvbGQucGZi.png A\n",
      "B 52912\n",
      "TmlraXNFRi1TZW1pQm9sZEl0YWxpYy5vdGY=.png B\n",
      "C 52912\n",
      "D 52912\n",
      "VHJhbnNpdCBCb2xkLnR0Zg==.png D\n",
      "E 52912\n",
      "F 52912\n",
      "G 52912\n",
      "H 52912\n",
      "I 52912\n",
      "J 52911\n",
      "529114\n",
      "A 1872\n",
      "B 1873\n",
      "C 1873\n",
      "D 1873\n",
      "E 1873\n",
      "F 1872\n",
      "G 1872\n",
      "H 1872\n",
      "I 1872\n",
      "J 1872\n",
      "18724\n",
      "(529114, 784) (529114, 10)\n",
      "(18724, 784) (18724, 10)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = list(), list()\n",
    "x_test, y_test = list(), list()\n",
    "\n",
    "train_letters = os.listdir(\"./notMNIST_large\")\n",
    "test_letters = os.listdir(\"./notMNIST_small\")\n",
    "\n",
    "count = 0;\n",
    "for i, letter in enumerate(train_letters):\n",
    "    fonts = os.listdir(\"./notMNIST_large/\" + letter)\n",
    "    print(str(letter)+ \" \" + str(len(fonts)))\n",
    "    for j, font in enumerate(fonts):\n",
    "        img = None\n",
    "        try:\n",
    "            img = plt.imread(\"./notMNIST_large/\"+ letter + \"/\" + font)\n",
    "        except:\n",
    "            print(font + \" \" + letter)\n",
    "        if img is None :\n",
    "            count -= 1\n",
    "            continue\n",
    "        x_train.append(img.reshape([28*28]))\n",
    "        y_train.append(np.zeros(10))\n",
    "        y_train[count + j][i] = 1\n",
    "    count += len(fonts)\n",
    "print(count)\n",
    "\n",
    "count = 0;\n",
    "for i, letter in enumerate(test_letters):\n",
    "    fonts = os.listdir(\"./notMNIST_small/\" + letter)\n",
    "    print(str(letter)+ \" \" + str(len(fonts)))\n",
    "    for j, font in enumerate(fonts):\n",
    "        img = None\n",
    "        try:\n",
    "            img = plt.imread(\"./notMNIST_small/\"+ letter + \"/\" + font)\n",
    "        except:\n",
    "            print(font + \" \" + letter)\n",
    "            #plt.imshow(img)\n",
    "        #plt.imshow(img)\n",
    "        if img is None :\n",
    "            count -= 1\n",
    "            continue\n",
    "        x_test.append(img.reshape([28*28]))\n",
    "        y_test.append(np.zeros(10))\n",
    "        y_test[count + j][i] = 1\n",
    "    count += len(fonts)\n",
    "print(count)\n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "x_test = np.asarray(x_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(a,b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = shuffle(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = int(np.random.rand(1) * 18724)\n",
    "plt.imshow(x_train[i].reshape([28,28]))\n",
    "print(y_train[i])\n",
    "time.sleep(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    layers = list()\n",
    "    \n",
    "    w = list()\n",
    "    b = list()\n",
    "    \n",
    "    a = list()\n",
    "    z = list()\n",
    "    \n",
    "    da = list()\n",
    "    db = list()\n",
    "    dw = list()\n",
    "    \n",
    "    activators = list()\n",
    "    \n",
    "    depth = 0\n",
    "    \n",
    "    def relu(self, x):\n",
    "        return np.maximum(0,x)\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def drelu(self, x):\n",
    "        return x > 0\n",
    "    \n",
    "    def dsigmoid(self, x):\n",
    "        sigx = self.sigmoid(x)\n",
    "        return np.multiply(sigx, (1 - sigx))\n",
    "    \n",
    "    def __init__(self, input_size, layers_count, layers_size, activators, l_rate = 0.01):\n",
    "        self.layers = list()\n",
    "        self.w = list()\n",
    "        self.b = list()\n",
    "        self.a = list()\n",
    "        self.z = list()\n",
    "        \n",
    "        self.activators = activators\n",
    "        self.l_rate = l_rate\n",
    "        \n",
    "        self.layers.append(input_size)\n",
    "        self.a.append(0)\n",
    "        self.z.append(0)\n",
    "        for x in range(0,layers_count):\n",
    "            self.layers.append(layers_size[x])\n",
    "            self.a.append(0)\n",
    "            self.z.append(0)\n",
    "        \n",
    "        self.depth = len(self.layers)\n",
    "        \n",
    "        for x in range(1, self.depth):\n",
    "            #matarr = np.ndarray(shape=(self.layers[x-1], self.layers[x]))\n",
    "            matarr = np.random.normal(0,0.5, (self.layers[x-1], self.layers[x]))\n",
    "            mat = np.matrix(matarr)\n",
    "            self.w.append(mat)\n",
    "            #print(mat)\n",
    "            #barr = np.ndarray(self.layers[x])\n",
    "            barr = np.random.normal(0,0.5, self.layers[x])\n",
    "            #print(barr.shape)\n",
    "            #barr = barr.reshape((barr.shape[0], 1))\n",
    "            self.b.append(barr)\n",
    "        \n",
    "        \n",
    "    def predict(self,input):\n",
    "        self.a[0] = input\n",
    "        #print(self.a[0])\n",
    "        \n",
    "        for x in range(1,self.depth):\n",
    "            self.z[x] = np.matmul(self.a[x - 1], self.w[x - 1]) + self.b[x - 1]\n",
    "            if self.activators[x - 1] == \"sig\":\n",
    "                val = self.sigmoid(self.z[x])\n",
    "            elif self.activators[x - 1] == \"relu\":\n",
    "                val = self.relu(self.z[x])\n",
    "            self.a[x] = val\n",
    "            #print(\"wtf \" + str(x) + str(self.a[x]))\n",
    "        return self.a[self.depth - 1]\n",
    "    \n",
    "    def test(self, input, ans):\n",
    "        prediction = self.predict(input)\n",
    "        #c1 = np.array(list(np.array_equal(np.round(prediction[x]), ans[x]) for x in range(ans.shape[0])))\n",
    "        c1 = np.array(list(np.argmax(prediction[x]) == np.argmax(ans[x]) for x in range(ans.shape[0])))\n",
    "        #print(prediction)\n",
    "        \n",
    "        c = prediction - ans\n",
    "        c = np.square(c)\n",
    "        c = c.sum(axis = 1).mean()\n",
    "        return (c,c1.sum() / c1.shape[0])\n",
    "    \n",
    "    def train(self, input, ans):\n",
    "        prediction = self.predict(input)\n",
    "        #print(input.shape[0])\n",
    "        c = (prediction - ans)\n",
    "        c = np.square(c)\n",
    "        #print(c)\n",
    "        \n",
    "        prediction = np.swapaxes(prediction, 0,1)\n",
    "        ans = np.swapaxes(ans, 0,1)\n",
    "        \n",
    "        self.da = list() # dC(0)/da(Lj)\n",
    "        self.db = list() # dC(0)/db(Lj)\n",
    "        self.dw = list() # dC(0)/dw(Ljk)\n",
    "        \n",
    "        for i, x in enumerate(self.layers):\n",
    "            self.da.append(0)\n",
    "            self.db.append(0)\n",
    "            self.dw.append(0)\n",
    "        #print(len(self.db))\n",
    "        self.da[self.depth - 1] = 2 * (ans - prediction)\n",
    "        #print(self.da[self.depth - 1])\n",
    "        \n",
    "        #print(\"a\")\n",
    "        for x in range(self.depth - 2, 0, -1):\n",
    "            #print(x)\n",
    "            #print(self.w[x].shape, self.da[x+1].shape)\n",
    "            #a = np.asarray(np.matmul(self.w[x], da[x + 1]))\n",
    "            a = np.matmul(self.w[x], self.da[x + 1])\n",
    "            #print(a.shape)\n",
    "            #print(type(a))\n",
    "            #print(type(self.z[x]))\n",
    "            #print(a.shape, self.z[x].shape)\n",
    "            if self.activators[x - 1] == \"sig\":\n",
    "                #a = np.multiply(a, np.asarray(self.dsigmoid(self.z[x])))\n",
    "                a = np.multiply(a, np.swapaxes(self.dsigmoid(self.z[x]), 0, 1))\n",
    "            elif self.activators[x - 1] == \"relu\":\n",
    "                #a = np.multiply(a, np.asarray(self.drelu(self.z[x])))\n",
    "                a = np.multiply(a, np.swapaxes(self.drelu(self.z[x]), 0, 1))\n",
    "            #print(a)\n",
    "            #print(a.shape)\n",
    "            self.da[x] = a\n",
    "        #print(\"b\")\n",
    "        for x in range(1, self.depth):\n",
    "            #print(x)\n",
    "            if self.activators[x - 1] == \"sig\":\n",
    "                #a = np.multiply(a, np.asarray(self.dsigmoid(self.z[x])))\n",
    "                b = np.multiply(self.da[x], np.swapaxes(self.dsigmoid(self.z[x]), 0, 1))\n",
    "            elif self.activators[x - 1] == \"relu\":\n",
    "                #a = np.multiply(a, np.asarray(self.drelu(self.z[x])))\n",
    "                b = np.multiply(self.da[x], np.swapaxes(self.drelu(self.z[x]), 0, 1))\n",
    "            #print(b)\n",
    "            \n",
    "            self.db[x] = b\n",
    "            self.db[x] = np.mean(self.db[x], axis = 1)\n",
    "            #print(self.db[x].shape)\n",
    "            \n",
    "        #print(\"w\")\n",
    "        for x in range(1, self.depth):\n",
    "            \n",
    "            \n",
    "            _a = np.swapaxes(self.a[x - 1], 0, 1)\n",
    "            \n",
    "            w = np.zeros((_a.shape[0], self.da[x].shape[0], _a.shape[1]))\n",
    "            \n",
    "            for k in range(_a.shape[0]):\n",
    "                for j in range(self.da[x].shape[0]):\n",
    "                    w[k][j] = np.multiply(_a[k], self.da[x][j])\n",
    "            \n",
    "            self.dw[x] = w\n",
    "            self.dw[x] = np.mean(self.dw[x], axis = 2)\n",
    "            #print(self.dw[x].shape)\n",
    "        \n",
    "        for x in range(1, self.depth):\n",
    "            self.w[x - 1] += self.dw[x] * self.l_rate\n",
    "            \n",
    "            self.b[x - 1] = np.reshape(self.b[x - 1], (self.b[x - 1].shape[0], 1))\n",
    "            self.b[x - 1] += self.db[x] * self.l_rate\n",
    "            self.b[x - 1] = np.squeeze(self.b[x - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(784,2,(16,10), (\"relu\", \"sig\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = nn.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.1612300252439187, 0.12840522080307834)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.train(x_train[:100], y_train[:100])\n",
    "nn.test(x_train, y_train)\n",
    "#nn.dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Batch:  575 Train accuracy:  (0.5580644964335529, 0.6569737334487464) Test accuracy:  (0.4884173266030588, 0.7224417859431745))\r"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "epochs = 10\n",
    "nn.l_rate = 0.01\n",
    "\n",
    "batches = x_train.shape[0] // batch_size\n",
    "#batch_length = int(np.floor(x_train.shape[0] / (batches)))\n",
    "for y in range(epochs):\n",
    "    for x in range(batches + 1):\n",
    "        if x == batches:\n",
    "            if x_train.shape[0] != batch_size * batches:\n",
    "                nn.train(x_train[batch_size * batches:], y_train[batch_size * batches:])\n",
    "            break\n",
    "        nn.train(x_train[batch_size * x : batch_size * (x + 1) - 1], y_train[batch_size * x : batch_size * (x + 1) - 1])\n",
    "        #print(\"a\")\n",
    "        print(\"Epoch: \", y, \"Batch: \", x ,\"Train accuracy: \", nn.test(x_train, y_train), \"Test accuracy: \", nn.test(x_test, y_test), end=\"\\r\")\n",
    "    #print(\"epoch finished!\")\n",
    "    x_train, y_train = shuffle(x_train,y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
